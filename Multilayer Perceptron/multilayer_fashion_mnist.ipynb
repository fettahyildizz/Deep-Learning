{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilayer_fashion_mnist.ipynb",
      "provenance": [],
      "mount_file_id": "1cHs9Ktuys97Eckd33t4Dk3-PySMaplEW",
      "authorship_tag": "ABX9TyPMRxVy5Dija2iH5VMObVqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fettahyildizz/Deep-Learning/blob/main/Multilayer%20Perceptron/multilayer_fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JRd59SHjswt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysEE1LKvjs5B"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZUvaXwgq_wZ",
        "outputId": "3132332b-0e62-4806-e862-958cd6e61903"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "x_train = x_train[:6000]\n",
        "x_test = x_test[:6000]\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJkLXD_UkEDy"
      },
      "source": [
        "class BackPropogation:\n",
        "    def __init__(self,class_number, learning_rate1, learning_rate2, learning_rate3, n_epoch, n_layer, n_neuron1, n_neuron2,\n",
        "                 momentum):\n",
        "        self.momentum = momentum\n",
        "        self.learning_rate1 = learning_rate1\n",
        "        self.learning_rate2 = learning_rate2\n",
        "        self.learning_rate3 = learning_rate3\n",
        "        self.accuracy = list()\n",
        "        self.class_number = class_number\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_layer = n_layer\n",
        "        self.n_neuron1 = n_neuron1\n",
        "        self.n_neuron2 = n_neuron2\n",
        "        self.bias = np.ones(1)\n",
        "\n",
        "        self.activation_func = self.sigmfunc\n",
        "        self.weight0 = None\n",
        "        self.weight1 = None\n",
        "        self.weight2 = None\n",
        "\n",
        "    def sigmfunc(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigturev(self, x):\n",
        "        return (1 / (1 + np.exp(-x))) * (1 - (1 / (1 + np.exp(-x))))\n",
        "\n",
        "    def train(self, X, yd):\n",
        "        \n",
        "        self.weight1 = np.random.uniform(-0.15, 0.15, (\n",
        "            self.n_neuron1, X[0].size + 1))  # İlk ağırlıkları -0.15,0.15 arasında rastgele seçeriz\n",
        "        self.weight2 = np.random.uniform(-0.15, 0.15, (self.n_neuron2, self.n_neuron1 + 1))\n",
        "        self.weight0 = np.random.uniform(-0.15, 0.15, (self.class_number, self.n_neuron2 + 1))\n",
        "        self.grad0 = None\n",
        "        self.grad1 = None\n",
        "        self.grad2 = None\n",
        "        self.old_weight1 = self.weight1\n",
        "        self.old_weight2 = self.weight2\n",
        "        self.old_weight0 = self.weight0\n",
        "        self.older_weight1 = self.weight1\n",
        "        self.older_weight2 = self.weight2\n",
        "        self.older_weight0 = self.weight0\n",
        "\n",
        "        for i in range(self.n_epoch):\n",
        "            self.error_list = list()\n",
        "            for idx, image in enumerate(X):\n",
        "                \n",
        "                self.older_weight1 = self.old_weight1\n",
        "                self.older_weight2 = self.old_weight2\n",
        "                self.older_weight0 = self.old_weight0\n",
        "                self.old_weight1 = self.weight1\n",
        "                self.old_weight2 = self.weight2\n",
        "                self.old_weight0 = self.weight0\n",
        "\n",
        "                image_flatten = image.flatten()\n",
        "                image_flatten = image_flatten / 255  # Normalize\n",
        "                \n",
        "                self.image_x_biased = np.concatenate((image_flatten, self.bias))  # AĞIRLIĞA BIAS EKLENIR\n",
        "                self.image_x = np.transpose(np.array([self.image_x_biased]))  # x inputları düzenli hale getirilir\n",
        "                self.v1 = np.matmul(self.weight1, self.image_x)\n",
        "                self.y1 = self.sigmfunc(self.v1)\n",
        "                self.y1_x = np.vstack(\n",
        "                    (self.y1, self.bias))  # ikinci katman için birinci katman çıkışlarına bias eklenir.\n",
        "                self.y1_x_t = np.transpose(self.y1_x)\n",
        "\n",
        "                self.v2 = np.matmul(self.weight2, self.y1_x)\n",
        "                self.y2 = self.sigmfunc(self.v2)\n",
        "                self.y2_x = np.vstack((self.y2, self.bias))\n",
        "                self.y2_x_t = np.transpose(self.y2_x)\n",
        "\n",
        "                \n",
        "\n",
        "                self.v0 = np.matmul(self.weight0, self.y2_x)\n",
        "                self.y0 = self.sigmfunc(self.v0)\n",
        "                yd_temp = np.array(yd[idx])\n",
        "                \n",
        "                yd_temp = np.transpose([yd_temp])\n",
        "                self.e = yd_temp - self.y0\n",
        "                \n",
        "                self.e_temp = np.array([self.e])\n",
        "                self.et = np.transpose(self.e)\n",
        "                self.E = (1 / 2) * np.matmul(self.et, self.e)\n",
        "                \n",
        "                self.error_list.append(float(self.E))\n",
        "\n",
        "                self.grad0 = self.e * self.sigturev(self.v0)\n",
        "\n",
        "                self.weight0_c = np.delete(self.weight0, -1, 1)  # ağırlığın son sütununu çıkarıp tranzpozesi alınır\n",
        "                self.weight0_c_t = np.transpose(self.weight0_c)\n",
        "                self.grad2 = np.dot(self.weight0_c_t, self.grad0) * self.sigturev(self.v2)\n",
        "\n",
        "                self.weight2_c = np.delete(self.weight2, -1, 1)\n",
        "                self.weight2_c_t = np.transpose(self.weight2_c)\n",
        "                self.grad1 = np.dot(self.weight2_c_t, self.grad2) * self.sigturev(self.v1)\n",
        "\n",
        "                self.grad0_np = np.array([self.grad0])\n",
        "                self.grad0_np = np.transpose(self.grad0_np)\n",
        "                self.grad1_np = np.array([self.grad1])\n",
        "                self.grad1_np = np.transpose(self.grad1_np)\n",
        "                self.grad2_np = np.array([self.grad2])\n",
        "                self.grad2_np = np.transpose(self.grad2_np)\n",
        "\n",
        "                self.y2_x_t = np.transpose(self.y2_x)\n",
        "                self.y1_x_t = np.transpose(self.y1_x)\n",
        "                self.image_x_t = np.array([self.image_x_biased])\n",
        "\n",
        "                ##################AĞIRLIK GÜNCELLEME\n",
        "                self.weight0 = self.weight0 + self.learning_rate3 * np.matmul(self.grad0,\n",
        "                                                                              self.y2_x_t) + self.momentum * (\n",
        "                                       self.old_weight0 - self.older_weight0)  # y2_x_t\n",
        "                self.weight2 = self.weight2 + self.learning_rate2 * np.matmul(self.grad2,\n",
        "                                                                              self.y1_x_t) + self.momentum * (\n",
        "                                       self.old_weight2 - self.older_weight2)\n",
        "                self.weight1 = self.weight1 + self.learning_rate1 * np.matmul(self.grad1,\n",
        "                                                                              self.image_x_t) + self.momentum * (\n",
        "                                       self.old_weight1 - self.older_weight1)\n",
        "\n",
        "            self.accuracy.append(sum(self.error_list) / len(self.error_list))\n",
        "            print(\"Epoch: \" + str(i + 1) + \"Loss: \" + str(self.accuracy[i]))\n",
        "\n",
        "    def fit(self, test, test_label):\n",
        "        accuracy = 0\n",
        "        for idx, tst in enumerate(test):\n",
        "            image_flatten = tst.flatten()\n",
        "            image_x_biased = np.concatenate((image_flatten, self.bias))\n",
        "            image_x_t = np.array([image_x_biased])\n",
        "            image_x = np.transpose(np.array([image_x_biased]))  # x inputs\n",
        "            v1 = np.matmul(self.weight1, image_x)\n",
        "            y1 = self.sigmfunc(v1)\n",
        "            y1_x = np.vstack((y1, self.bias))  # ikinci katman için birinci katman çıkışlarına bias eklenir.\n",
        "            y1_x_t = np.transpose(y1_x)\n",
        "\n",
        "            v2 = np.matmul(self.weight2, y1_x)\n",
        "            y2 = self.sigmfunc(v2)\n",
        "            y2_x = np.vstack((y2, self.bias))\n",
        "            y2_x_t = np.transpose(y2_x)\n",
        "\n",
        "            v0 = np.matmul(self.weight0, y2_x)\n",
        "            y0 = self.sigmfunc(v0)\n",
        "\n",
        "            # print(y0)\n",
        "            # if(y0==)\n",
        "            index_max = np.argmax(y0)\n",
        "            test_label_temp = np.argmax(test_label[idx])\n",
        "            if(index_max == test_label_temp):\n",
        "                accuracy += 1\n",
        "        print(\"Evaluated accuracy: \"+ str(accuracy/len(test)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f39mlfLilhSO",
        "outputId": "1855cf4f-17ff-486f-ffaf-27de11238944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "neuralNetwork = BackPropogation(class_number = 10, learning_rate1=0.2,learning_rate2=0.2,learning_rate3=0.2, n_epoch=25, n_layer=2, n_neuron1=60, n_neuron2=30, momentum=0.4)\n",
        "neuralNetwork.train(x_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch sayısı: 1Ortalama loss: 0.2975930246537047\n",
            "Epoch sayısı: 2Ortalama loss: 0.17724396293693356\n",
            "Epoch sayısı: 3Ortalama loss: 0.14764113641098156\n",
            "Epoch sayısı: 4Ortalama loss: 0.13527889904852067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-69f2e2b20916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mneuralNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropogation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neuron1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neuron2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mneuralNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-b0d422b84096>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, yd)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_x_biased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# AĞIRLIĞA BIAS EKLENIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_x_biased\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x inputları düzenli hale getirilir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 self.y1_x = np.vstack(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2c3qi2gYsTT"
      },
      "source": [
        "plt.im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XabG8fEPQ53b",
        "outputId": "68a0de03-dc6c-4256-b093-397519522ed7"
      },
      "source": [
        "neuralNetwork.fit(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluated accuracy: 0.7971666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKVl7_GFlsHS"
      },
      "source": [
        "plt.title(\"Ani hata değerleri - Epoch:25 -1.Katman:60, 2.Katman:30 nöron-Öğrenme katsayısı:0.2-0.2-0.2 Momentum:0.4\")\n",
        "plt.xlabel(\"Epoch sayısı\")\n",
        "plt.ylabel(\"Ani hata değeri\")\n",
        "plt.plot(neuralNetwork.accuracy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}